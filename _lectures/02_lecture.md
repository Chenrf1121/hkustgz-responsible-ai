---
type: lecture
date: 2025-09-08T10:00:00+8:00
title: Lecture 2 - Transformer and Vision Models
tldr: "Deep dive into Transformer architecture and its applications in computer vision, including ViT, CLIP, SAM, and multi-modal models"
thumbnail: /static_files/presentations/lec.jpg
links:
    - url: /static_files/presentations/lecture_2.pptx
      name: slides
---
**Topics Covered:**
- **Transformer Architecture**: Positional embedding, Multi-head attention, Feed-forward layers, Residual connections, Layer normalization
- **Vision Transformer (ViT)**: Applying transformers to images, patch embedding, scaling laws
- **ViT Variants**: MAE (self-supervised pre-training), Swin Transformer (multi-scale patches), DeiT (distillation)
- **CLIP**: Contrastive language-image pre-training, zero-shot classification
- **SAM**: Segment Anything Model, promptable segmentation
- **LLaVA**: Visual instruction tuning, multi-modal reasoning
- **Responsibility Issues**: Uncertainty estimation, out-of-distribution detection, fairness, hallucination
