---
type: lecture
date: 2025-10-06T10:00:00+8:00
title: Lecture 6 - Backdoor Attacks in AI
tldr: "Backdoor Attacks, a form of data poisoning where a model is trained to behave normally on clean data but perform specific malicious actions when a hidden trigger is present."
thumbnail: /static_files/presentations/lec.jpg
links:
    - url: /static_files/presentations/lecture_6.pdf
      name: slides
---
**Topics Covered:**
- Backdoor Attack Mechanism
- Attack vs. Adversarial Examples
- Poisoning Strategies
